{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"word2vec_train.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOnKLCNCN1n7+gc8G0TMmJf"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fVFN1FGwR7mk"},"source":["# Word2vec train using gensim\r\n","\r\n","In this notebook, we simply read paragraphs and train word2vecs(using gensim.models.Word2Vec).\r\n","\r\n","we use these pre-trained vectors in Language models.  "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fyo_pPPaonyC","executionInfo":{"status":"ok","timestamp":1610984662290,"user_tz":-240,"elapsed":16247,"user":{"displayName":"demetre pipia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4CbIRo9dennmXZMhW6FoV-wXK_9w-s1pDeMNv=s64","userId":"11756928928575830424"}},"outputId":"a01cc8ae-44c5-458a-f27b-41750c2047b0"},"source":["!pip install -U gensim\r\n","!pip install -U mosestokenizer"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting gensim\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/e0/fa6326251692056dc880a64eb22117e03269906ba55a6864864d24ec8b4e/gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n","\u001b[K     |████████████████████████████████| 24.2MB 44.8MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (4.1.0)\n","Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n","Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.19.5)\n","Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n","Installing collected packages: gensim\n","  Found existing installation: gensim 3.6.0\n","    Uninstalling gensim-3.6.0:\n","      Successfully uninstalled gensim-3.6.0\n","Successfully installed gensim-3.8.3\n","Collecting mosestokenizer\n","  Downloading https://files.pythonhosted.org/packages/4b/b3/c0af235b16c4f44a2828ef017f7947d1262b2646e440f85c6a2ff26a8c6f/mosestokenizer-1.1.0.tar.gz\n","Requirement already satisfied, skipping upgrade: docopt in /usr/local/lib/python3.6/dist-packages (from mosestokenizer) (0.6.2)\n","Collecting openfile\n","  Downloading https://files.pythonhosted.org/packages/93/e6/805db6867faacb488b44ba8e0829ef4de151dd0499f3c5da5f4ad11698a7/openfile-0.0.7-py3-none-any.whl\n","Collecting uctools\n","  Downloading https://files.pythonhosted.org/packages/04/cb/70ed842d9a43460eedaa11f7503b4ab6537b43b63f0d854d59d8e150fac1/uctools-1.3.0.tar.gz\n","Collecting toolwrapper\n","  Downloading https://files.pythonhosted.org/packages/41/7b/34bf8fb69426d8a18bcc61081e9d126f4fcd41c3c832072bef39af1602cd/toolwrapper-2.1.0.tar.gz\n","Building wheels for collected packages: mosestokenizer, uctools, toolwrapper\n","  Building wheel for mosestokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mosestokenizer: filename=mosestokenizer-1.1.0-cp36-none-any.whl size=49120 sha256=963f2a137db8581859f88cb61dfa32a80cee378ed32f67643fc218297013d4f1\n","  Stored in directory: /root/.cache/pip/wheels/a2/e7/48/48d5e0f9c0cd5def2dfd7cb8543945f906448ed1313de24a29\n","  Building wheel for uctools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for uctools: filename=uctools-1.3.0-cp36-none-any.whl size=6163 sha256=9229684755f5ed7aa9fd22f9b239d61936d922da1076e8ca7e539def8487a3db\n","  Stored in directory: /root/.cache/pip/wheels/06/b6/8f/935d5bf5bca85d47c6f5ec31641879bba057d336ab36b1e773\n","  Building wheel for toolwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for toolwrapper: filename=toolwrapper-2.1.0-cp36-none-any.whl size=3356 sha256=e3eb9e6605cacdde9ab33c72b38b4a1523f7cee739c10c71a7c2438b242aa816\n","  Stored in directory: /root/.cache/pip/wheels/84/ea/29/e02f3b855bf19344972092873a1091b329309bbc3d3d0cbaef\n","Successfully built mosestokenizer uctools toolwrapper\n","Installing collected packages: openfile, uctools, toolwrapper, mosestokenizer\n","Successfully installed mosestokenizer-1.1.0 openfile-0.0.7 toolwrapper-2.1.0 uctools-1.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"APKJ-MZ-IWYk","executionInfo":{"status":"ok","timestamp":1610984692460,"user_tz":-240,"elapsed":1801,"user":{"displayName":"demetre pipia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4CbIRo9dennmXZMhW6FoV-wXK_9w-s1pDeMNv=s64","userId":"11756928928575830424"}}},"source":["import pandas as pd\n","from mosestokenizer import *\n","from gensim.models import Word2Vec\n","from tqdm import tqdm"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10LeGdpIGpey","executionInfo":{"status":"ok","timestamp":1610984714522,"user_tz":-240,"elapsed":20867,"user":{"displayName":"demetre pipia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4CbIRo9dennmXZMhW6FoV-wXK_9w-s1pDeMNv=s64","userId":"11756928928575830424"}},"outputId":"de21987a-90f2-413b-9960-7a67d0f04bc4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jwkbfEOVGhZr","executionInfo":{"status":"ok","timestamp":1610984772237,"user_tz":-240,"elapsed":41937,"user":{"displayName":"demetre pipia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4CbIRo9dennmXZMhW6FoV-wXK_9w-s1pDeMNv=s64","userId":"11756928928575830424"}}},"source":["# We need to specify the number of rows, otherwise There will not be enough ram\r\n","sen_df = pd.read_csv('/content/drive/MyDrive/demetre_{pipia, uridia}/data/paragraph_all_only_georgian_shuffled.csv', lineterminator='\\n', nrows=3000000)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"dsnRmKaVIa3o","executionInfo":{"status":"ok","timestamp":1610984776961,"user_tz":-240,"elapsed":688,"user":{"displayName":"demetre pipia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4CbIRo9dennmXZMhW6FoV-wXK_9w-s1pDeMNv=s64","userId":"11756928928575830424"}},"outputId":"1c03edf1-03cd-42f2-f8d6-1c5d17cdf8b3"},"source":["sen_df.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Paragraph</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>რა თქმა უნდა , ბევრი საინტერესო , ჭკვიანი , კა...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>მზის შთამომავლები 2016 წლის სამხრეთ კორეული ტე...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ახლაც მესმის მსახიობ ჟანრი ლოლაშვილის ხმა , ახ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>აღმოსავლეთ ევროპის ინსტიტუტში ელიტური კორუფციი...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>დაავადების სიმძიმისა და ხასიათის მიხედვით , ნე...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           Paragraph\n","0  რა თქმა უნდა , ბევრი საინტერესო , ჭკვიანი , კა...\n","1  მზის შთამომავლები 2016 წლის სამხრეთ კორეული ტე...\n","2  ახლაც მესმის მსახიობ ჟანრი ლოლაშვილის ხმა , ახ...\n","3  აღმოსავლეთ ევროპის ინსტიტუტში ელიტური კორუფციი...\n","4  დაავადების სიმძიმისა და ხასიათის მიხედვით , ნე..."]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"K44ZhkY2T4IZ"},"source":["tokenizer = MosesTokenizer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L2TEjJqqR6JH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610821426894,"user_tz":-240,"elapsed":2213,"user":{"displayName":"demetre pipia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4CbIRo9dennmXZMhW6FoV-wXK_9w-s1pDeMNv=s64","userId":"11756928928575830424"}},"outputId":"847e1695-fc7b-49a1-95f0-e7e38944e252"},"source":["sentences = sen_df['Paragraph'].tolist()\n","sentences = list(filter(lambda x: \"\\n\" not in x, list(sentences)))\n","len(sentences)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3000000"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"iSvpQvrhRZZd"},"source":["tokenize every paragraph to prepare it for gensim.Word2vec"]},{"cell_type":"code","metadata":{"id":"t97gLwlRT0y8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610822046514,"user_tz":-240,"elapsed":617522,"user":{"displayName":"demetre pipia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4CbIRo9dennmXZMhW6FoV-wXK_9w-s1pDeMNv=s64","userId":"11756928928575830424"}},"outputId":"6c68d74a-fb09-4638-bbe2-ddffbe2d9c00"},"source":["sentences = [tokenizer(sentence) for sentence in tqdm(sentences)]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 3000000/3000000 [10:16<00:00, 4864.66it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IhgKlfJHWSaU","executionInfo":{"status":"ok","timestamp":1610730400792,"user_tz":-240,"elapsed":633935,"user":{"displayName":"demetre pipia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4CbIRo9dennmXZMhW6FoV-wXK_9w-s1pDeMNv=s64","userId":"11756928928575830424"}},"outputId":"e9c2443f-b3f4-424c-f100-cf28e6098093"},"source":["sentences[6]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['გადაზიდვა',\n"," 'გთავაზობთ',\n"," 'სააგენტო',\n"," 'და',\n"," 'საექსპედიტორო',\n"," 'სამუშაოებს',\n"," 'ბათუმის',\n"," ',',\n"," 'ფოთისა',\n"," 'საზღვაო',\n"," 'სავაჭრო',\n"," 'ნავსადგურებში',\n"," ',',\n"," '113']"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"CnHbW-3sJt0n","colab":{"base_uri":"https://localhost:8080/","height":303},"executionInfo":{"status":"error","timestamp":1610821164563,"user_tz":-240,"elapsed":2184,"user":{"displayName":"demetre pipia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4CbIRo9dennmXZMhW6FoV-wXK_9w-s1pDeMNv=s64","userId":"11756928928575830424"}},"outputId":"ae360433-f2bb-4046-ccc3-1e643424bbdc"},"source":["word2vec = Word2Vec(sentences=sentences, window=5, min_count=5, workers=4, iter=30)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-6a3251a303a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, max_final_vocab)\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             seed=seed, hs=hs, negative=negative, cbow_mean=cbow_mean, min_alpha=min_alpha, compute_loss=compute_loss)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m     def _do_train_epoch(self, corpus_file, thread_id, offset, cython_vocab, thread_private_mem, cur_epoch,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, ns_exponent, cbow_mean, min_alpha, compute_loss, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You can't pass a generator as the sentences argument. Try a sequence.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m             self.train(\n\u001b[1;32m    747\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, sentences, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    920\u001b[0m         \"\"\"\n\u001b[1;32m    921\u001b[0m         total_words, corpus_count = self.vocabulary.scan_vocab(\n\u001b[0;32m--> 922\u001b[0;31m             sentences=sentences, corpus_file=corpus_file, progress_per=progress_per, trim_rule=trim_rule)\n\u001b[0m\u001b[1;32m    923\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mscan_vocab\u001b[0;34m(self, sentences, corpus_file, progress_per, workers, trim_rule)\u001b[0m\n\u001b[1;32m   1401\u001b[0m             \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLineSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1403\u001b[0;31m         \u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scan_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         logger.info(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_scan_vocab\u001b[0;34m(self, sentences, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m   1384\u001b[0m                     \u001b[0msentence_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m                 )\n\u001b[0;32m-> 1386\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m                 \u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0mtotal_words\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"6FAjSw8QJXEY"},"source":["# after train we save vectors with a specific name\r\n","word2vec.save(\"/content/drive/MyDrive/demetre_{pipia, uridia}/resources/word2vec.model_name\")"],"execution_count":null,"outputs":[]}]}